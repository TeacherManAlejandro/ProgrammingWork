{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEXT_COLUMN = 'text'\n",
    "Y_COLUMN = 'author'\n",
    "TRAIN_DATA_FILE = \"train_data_spooky_author.csv\"\n",
    "SMALLER_SAMPLE_SIZE = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the DF, but split out the first 500 of each author (so reduce our dataset to 1500 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = pd.read_csv(TRAIN_DATA_FILE)\n",
    "gb = all_texts.groupby(Y_COLUMN)\n",
    "train_df = pd.DataFrame()\n",
    "validation_df = pd.DataFrame()\n",
    "for author, df in gb:\n",
    "    train_df=pd.concat([train_df, df.head(SMALLER_SAMPLE_SIZE)])\n",
    "    validation_df = pd.concat([validation_df, df.iloc[SMALLER_SAMPLE_SIZE:SMALLER_SAMPLE_SIZE+1000]])\n",
    "\n",
    "train_df.sort_index(inplace=True)\n",
    "validation_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        True\n",
       "text      True\n",
       "author    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use SpaCy to parse the words in the df into SpaCy.doc objects and add them to the smaller text sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "NLP = spacy.load('en', disable=['parser', 'ner'])\n",
    "doc = [d for d in NLP.pipe(train_df[TEXT_COLUMN].values)]\n",
    "train_df['doc'] = doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the doc that we just added to the dataframe, get the parts of speech for each text sample.\n",
    "Add a list of the parts of speech to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>doc</th>\n",
       "      <th>parts_of_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>(This, process, ,, however, ,, afforded, me, n...</td>\n",
       "      <td>DET NOUN PUNCT ADV PUNCT VERB PRON DET NOUN AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>(It, never, once, occurred, to, me, that, the,...</td>\n",
       "      <td>PRON ADV ADV VERB ADP PRON ADP DET NOUN VERB V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "      <td>(In, his, left, hand, was, a, gold, snuff, box...</td>\n",
       "      <td>ADP ADJ ADJ NOUN VERB DET ADJ NOUN NOUN PUNCT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "      <td>(How, lovely, is, spring, As, we, looked, from...</td>\n",
       "      <td>ADV ADJ VERB NOUN ADP PRON VERB ADP PROPN PROP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "      <td>(Finding, nothing, else, ,, not, even, gold, ,...</td>\n",
       "      <td>VERB NOUN ADV PUNCT ADV ADV NOUN PUNCT DET PRO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author  \\\n",
       "0  id26305  This process, however, afforded me no means of...    EAP   \n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
       "\n",
       "                                                 doc  \\\n",
       "0  (This, process, ,, however, ,, afforded, me, n...   \n",
       "1  (It, never, once, occurred, to, me, that, the,...   \n",
       "2  (In, his, left, hand, was, a, gold, snuff, box...   \n",
       "3  (How, lovely, is, spring, As, we, looked, from...   \n",
       "4  (Finding, nothing, else, ,, not, even, gold, ,...   \n",
       "\n",
       "                                     parts_of_speech  \n",
       "0  DET NOUN PUNCT ADV PUNCT VERB PRON DET NOUN AD...  \n",
       "1  PRON ADV ADV VERB ADP PRON ADP DET NOUN VERB V...  \n",
       "2  ADP ADJ ADJ NOUN VERB DET ADJ NOUN NOUN PUNCT ...  \n",
       "3  ADV ADJ VERB NOUN ADP PRON VERB ADP PROPN PROP...  \n",
       "4  VERB NOUN ADV PUNCT ADV ADV NOUN PUNCT DET PRO...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poslist = train_df['doc'].apply(lambda doc: \" \".join([token.pos_ for token in doc]))\n",
    "train_df['parts_of_speech'] = poslist\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "bigram_vector = vectorizer.fit_transform(train_df['parts_of_speech']).toarray()\n",
    "bigram_word_vector = vectorizer.fit_transform(train_df[TEXT_COLUMN]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 175)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create my test function, which runs a 5-fold stratified split and then validates on the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfolds log losses: ['0.766', '0.776', '0.809', '0.858', '0.916']\n",
      "mean log loss: 0.825\n",
      "kfolds accuracy: ['0.587', '0.637', '0.637', '0.653', '0.69']\n",
      "mean accuracy: 0.641\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X=bigram_word_vector\n",
    "y=train_df[Y_COLUMN]\n",
    "rskf = StratifiedKFold(n_splits=5, random_state=1)\n",
    "losses, accuracy = [], []\n",
    "nlp_pipeline = LogisticRegression()\n",
    "rskf\n",
    "\n",
    "for train_index, test_index in rskf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        assert not y_train.isnull().any()\n",
    "        nlp_pipeline.fit(X_train, y_train)\n",
    "        predictions = nlp_pipeline.predict(X_test)\n",
    "        \n",
    "        accuracy.append(metrics.accuracy_score(y_test, predictions))\n",
    "        losses.append(metrics.log_loss(y_test, nlp_pipeline.predict_proba(X_test)))\n",
    "\n",
    "print(f'kfolds log losses: {str([str(round(x, 3)) for x in sorted(losses)])}')\n",
    "print(f'mean log loss: {round(pd.np.mean(losses), 3)}')\n",
    "print(f'kfolds accuracy: {str([str(round(x, 3)) for x in sorted(accuracy)])}')\n",
    "print(f'mean accuracy: {round(pd.np.mean(accuracy), 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
